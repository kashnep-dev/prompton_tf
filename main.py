import time

import chat_with_news as cwn
import streamlit as st
from dotenv import load_dotenv
from langchain.schema import ChatMessage
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI
from streamlit_feedback import streamlit_feedback

from search import search_by_naver_api

load_dotenv()


@st.cache_data(ttl="2h", show_spinner=False)
def get_run_url(run_id):
    time.sleep(1)
    return client.read_run(run_id).url


st.sidebar.title(":books: :blue[  OO ì¦ê¶Œ]")
# expander = st.sidebar.markdown('## Requirements')

select_event = st.sidebar.selectbox('How do you want to find data?',
                                    ['ì¢…ëª©ë‰´ìŠ¤ ìš”ì•½', 'ì¬ë¬´ì •ë³´ ìš”ì•½', 'ì¦ê¶Œì•½ê´€ ì¡°íšŒ', 'ê¸°ì—… ë¶„ì„', 'ê¸°ìˆ ì  ë¶„ì„'])
#  ['Stock New Summary','inancial Information Summary','Document Analysis','Company Analysis','Techical Analysis'])


expander = st.sidebar.markdown('## Models and Parameters')
temperature = st.sidebar.slider('temperature Range (0.0 ~ 2.0 )', 0.0, 2.0, 0.2)  # min, max, default
model_name = st.sidebar.selectbox('chose a model name', ['gpt-3.5-turbo', 'gpt-4.0'])

if select_event == 'ì¢…ëª©ë‰´ìŠ¤ ìš”ì•½':
    st.title('Stock New Summary')
    st.markdown("""
                * _Stock News Sentiment Analysis_  
                *  Bing Search, Never News API ë“±ì„ í†µí•œ ì‚¬ì—…ì(ì¢…ëª©)ì— ëŒ€í•œ ë‰´ìŠ¤ ìš”ì•½ì„ í•´ë“œë¦½ë‹ˆë‹¤. 
                """)
    ########################################################
    # If user inputs a new prompt, generate and draw a new response
    msgs = StreamlitChatMessageHistory(key="langchain_messages")

    reset_history = st.sidebar.button("ì±„íŒ… ì´ˆê¸°í™”")
    if len(msgs.messages) == 0 or reset_history:
        msgs.clear()
        msgs.add_ai_message("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
        st.session_state["last_run"] = None

    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            ChatMessage(role="assistant", content="ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
        ]

    for msg in st.session_state.messages:
        st.chat_message(msg.role).write(msg.content)

    if user_input := st.chat_input():
        client, run_collector, cfg = cwn.configure_run()
        search_result = search_by_naver_api(user_input)

        st.session_state.messages.append(ChatMessage(role="user", content=user_input))
        st.chat_message("user").write(user_input)
        with st.chat_message("assistant"):
            stream_handler = cwn.StreamHandler(st.empty())
            llm = ChatOpenAI(streaming=True, callbacks=[stream_handler])
            prompt = cwn.make_prompt()
            chain = prompt | llm
            chain_with_history = RunnableWithMessageHistory(
                chain,
                lambda session_id: msgs,
                input_messages_key="question",
                history_messages_key="history",
            )
            response = chain_with_history.invoke({"question": user_input, "context": search_result}, cfg)
            st.session_state.messages.append(
                ChatMessage(role="assistant", content=response.content)
            )
        st.session_state.last_run = run_collector.traced_runs[0].id

    if st.session_state.get("last_run"):
        run_url = get_run_url(st.session_state.last_run)
        st.sidebar.markdown(f"[LangSmith ì¶”ì ğŸ› ï¸]({run_url})")
        feedback = streamlit_feedback(
            feedback_type="thumbs",
            optional_text_label=None,
            key=f"feedback_{st.session_state.last_run}",
        )
        if feedback:
            scores = {"ğŸ‘": 1, "ğŸ‘": 0}
            client.create_feedback(
                st.session_state.last_run,
                feedback["type"],
                score=scores[feedback["score"]],
                comment=feedback.get("text", None),
            )
            st.toast("í”¼ë“œë°±ì„ ì €ì¥í•˜ì˜€ìŠµë‹ˆë‹¤.!", icon="ğŸ“")
    ########################################################
elif select_event == 'ì¬ë¬´ì •ë³´ ìš”ì•½':
    st.title('Financial Information Summary')
    st.markdown("""
                """)
    context = st.text_input('ì‚¬ì—…ì(ì¢…ëª©)ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”')
    if st.button('ì¬ë¬´ì •ë³´ ìš”ì•½'):
        with st.spinner('[' + context + '] Searching ...'):
            st.text('ì¤€ë¹„ì¤‘ ì…ë‹ˆë‹¤.')

elif select_event == 'ì¦ê¶Œì•½ê´€ ì¡°íšŒ':
    st.title('Document Analysis')
    st.markdown("""
                """)
    uploaded_files = st.file_uploader("upload your file", type=['pdf', 'docx', 'pptx'], accept_multiple_files=True)
    process = st.button("Process")

    context = st.text_input('ê¶ê¸ˆí•˜ì‹  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”')
    if st.button('ì•½ê´€ë‚´ìš© ì¡°íšŒ'):
        with st.spinner('[' + context + '] Searching ...'):
            st.text('ì¤€ë¹„ì¤‘ ì…ë‹ˆë‹¤.')

elif select_event == 'ê¸°ì—… ë¶„ì„':
    st.title('Company Analysis')
    st.markdown("""
                """)
    uploaded_files = st.file_uploader("upload your file", type=['pdf', 'docx', 'pptx'], accept_multiple_files=True)
    process = st.button("Process")

    context = st.text_input('ì‚¬ì—…ì(ì¢…ëª©)ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”')
    if st.button('ê¸°ì—…ë¶„ì„'):
        with st.spinner('[' + context + '] Searching ...'):
            st.text('ì¤€ë¹„ì¤‘ ì…ë‹ˆë‹¤.')
else:
    st.title('Techical Analysis')
    st.markdown("""
                """)
    context = st.text_input('ì‚¬ì—…ì(ì¢…ëª©)ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”')
    if st.button('ì¢…ëª©ë¶„ì„'):
        with st.spinner('[' + context + '] Searching ...'):
            st.text('ì¤€ë¹„ì¤‘ ì…ë‹ˆë‹¤.')

expander = st.sidebar.expander("## About ")
expander.write(""" 
                Introducing Stock Summary and Financial Information Summarization with Generative AI (LLM)

                And Users can easily find the information they need in various documents, including securities terms and conditions.

                """)
