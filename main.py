import re
import time
from datetime import datetime

import streamlit as st
from dotenv import load_dotenv
from langchain.schema import ChatMessage
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI

import prompt as pt
import search
from config import ls_configure
from function_calling import run_conversation
from predict import PatternFinder, get_company_code

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Langsmith í™˜ê²½ì„¤ì •
client, run_collector, cfg = ls_configure()


# @st.cache_data(ttl="2h", show_spinner=False)
def get_run_url(run_id):
    time.sleep(1)
    return client.read_run(run_id).url


#
st.set_page_config(
    page_title="AI Securities Search",
    page_icon=":books:")

st.write("")
st.markdown("<h1 style='text-align: center;'>ì›í•˜ëŠ” íšŒì‚¬ì˜ ì£¼ì‹ì •ë³´ë¥¼</h1>", unsafe_allow_html=True)
st.markdown("<h1 style='text-align: center;'>ì¼ëª©ìš”ì—°í•˜ê²Œ</h1>", unsafe_allow_html=True)
st.markdown("<h1 style='text-align: center;'>ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.</h1>", unsafe_allow_html=True)
st.write("")
st.markdown("<p style='text-align: center; font-size: 20px;'>ì¢…ëª©ë‰´ìŠ¤/ì¬ë¬´ì •ë³´/ì£¼ì‹ì •ë³´/ì¦ê¶Œì•½ê´€ ë¶„ì„ </p>", unsafe_allow_html=True)
st.write("")

# If user inputs a new prompt, generate and draw a new response
msgs = StreamlitChatMessageHistory(key="langchain_messages")

temperature = 0.0
model_name = 'gpt-3.5-turbo'
uploaded_file = None
retriever, prompt = None, None

# sidebar êµ¬ì„±
with st.sidebar as sidebar:
    st.title(":books: :blue[  OO ì¦ê¶Œ]")
    st.markdown('## Models and Parameters')
    temperature = st.slider('temperature Range (0.0 ~ 1.0 )', 0.0, 1.0, 0.0)  # min, max, default
    model_name = st.selectbox('chose a model name', ['gpt-3.5-turbo', 'gpt-4'])
    # if st.session_state["select_event"] == 'ì¦ê¶Œì•½ê´€ ë¶„ì„':
    uploaded_file = st.sidebar.file_uploader("upload your pdf file", type=['pdf'])
    if uploaded_file:
        search_type = 'ì¦ê¶Œì•½ê´€ ë¶„ì„'
        retriever, prompt = pt.make_prompt_by_file('ì¦ê¶Œì•½ê´€ ë¶„ì„', uploaded_file)
    expander = st.expander("## About ")
    expander.write(""" 
                Introducing Stock Summary and Financial Information Summarization with Generative AI (LLM)
                And Users can easily find the information they need in various documents, including securities terms and conditions.
                """)
    reset_history = st.button("ì±„íŒ… ì´ˆê¸°í™”")

# main êµ¬ì„±

if len(msgs.messages) == 0 or reset_history:
    msgs.clear()
    msgs.add_ai_message("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    st.session_state["last_run"] = None

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        ChatMessage(role="assistant", content="ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    ]

for msg in st.session_state.messages:
    st.chat_message(msg.role).write(msg.content)

if user_input := st.chat_input():
    # ì˜ë„ë¶„ë¥˜ - function calling
    search_type, company, content = run_conversation(user_input)
    print(search_type, company, content)

    search_result = ''
    if search_type == 'get_news':
        search_result = search.search_by_naver_api(company)
    elif search_type == 'get_finance':
        search_result = search.search_by_dart_api(company)
    elif search_type == 'get_stock':
        start_date = datetime.today().strftime("%Y-%m-01")
        end_date = datetime.today().strftime("%Y-%m-%d")

        print(company)
        company_code_with_text = get_company_code(company)
        print("company_code_with_text : " + company_code_with_text)
        company_code = re.findall(r'\d+', company_code_with_text)
        print(company_code)
        print("company_code[0] : " + company_code[0])

        p = PatternFinder()
        p.set_stock(company_code[0])
        result = p.search(start_date, end_date)
        pred = p.stat_prediction(result)
        text = p.plot_pattern(result.index[1])

        search_result = """
                            ìš°ì„ 
                            {5}
                            ì—ì„œ Dateâ†’ë‚ ì§œ, Openâ†’ì‹œì‘ê°€ê²©, Highâ†’ìµœê³ ê°€ê²©, Lowâ†’ìµœì €ê°€ê²©, Closeâ†’ì¢…ê°€, Volumeâ†’ê±°ë˜ëŸ‰, Changeâ†’ë“±ë½ë¥  ë¡œ ëª…ì¹­ì„ ìˆ˜ì •í•´ì¤˜.
                            ê·¸ë¦¬ê³  ë°˜ë“œì‹œ 'í‘œ' í˜•íƒœë¡œ ì¶œë ¥í•´ì¤˜.
                            ìœ„ í‘œëŠ” {1}ë¶€í„° {2}ê¹Œì§€ {3}ì˜ ëŒ€í•œë¯¼êµ­ ì£¼ì‹ì¥ì´ ì—´ë¦° ë‚ ì˜ ì£¼ì‹ ê°€ê²©ì´ì•¼.
                            
                            {4}ì˜ ê°’ì´ ì–‘ìˆ˜ì¼ ê²½ìš° ë‹¤ìŒ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´ì¤˜. 'ì´ë²ˆ ë‹¬ ì£¼ê°€ë¥¼ ìœ ì‚¬ë„ 95%ì´ìƒì¸ ê³¼ê±° ì°¨íŠ¸ì— ëŒ€ì…ì‹œ 5ì¼í›„ ì£¼ê°€ëŠ” +{4} ìƒìŠ¹í•  ì˜ˆì •ì…ë‹ˆë‹¤.'
                            {4}ì˜ ê°’ì´ ìŒìˆ˜ì¼ ê²½ìš° ë‹¤ìŒ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´ì¤˜. 'ì´ë²ˆ ë‹¬ ì£¼ê°€ë¥¼ ìœ ì‚¬ë„ 95%ì´ìƒì¸ ê³¼ê±° ì°¨íŠ¸ì— ëŒ€ì…ì‹œ 5ì¼í›„ ì£¼ê°€ëŠ” -{4} í•˜ë½í•  ì˜ˆì •ì…ë‹ˆë‹¤.'
                        """.format('', start_date, end_date, company, str(text),
                                   search.get_monthly_price(company_code))

    st.session_state.messages.append(ChatMessage(role="user", content=user_input))
    st.chat_message("user").write(user_input)
    with st.chat_message("assistant"):
        stream_handler = pt.StreamHandler(st.empty())
        if company is None and search_type is None:
            if uploaded_file is not None:
                llm = ChatOpenAI(
                    model=model_name,
                    temperature=temperature,
                    streaming=True,
                    callbacks=[stream_handler]
                )
                chain = (
                        {
                            "context": retriever,
                            "question": RunnablePassthrough(),
                        }
                        | prompt
                        | llm
                )
                response = chain.invoke(user_input, cfg).content
            else:
                # response = content
                prompt_general = ChatPromptTemplate.from_messages(
                    [
                        ("system", content),
                        MessagesPlaceholder(variable_name="history"),
                        ("human", "{question}"),
                    ]
                )
                llm = ChatOpenAI(
                    model=model_name,
                    temperature=temperature,
                    streaming=True,
                    callbacks=[stream_handler]
                )
                chain = prompt_general | llm
                chain_with_history = RunnableWithMessageHistory(
                    chain,
                    lambda session_id: msgs,
                    input_messages_key="question",
                    history_messages_key="history",
                )
                response = chain_with_history.invoke({"question": user_input}, cfg).content
        else:
            chain = pt.chain_with_api(search_type, model_name, temperature)
            chain_with_history = RunnableWithMessageHistory(
                chain,
                lambda session_id: msgs,
                input_messages_key="question",
                history_messages_key="history",
            )
            response = chain_with_history.invoke({"question": user_input, "context": search_result}, cfg).content
        st.session_state.last_run = run_collector.traced_runs[0].id
        st.session_state.messages.append(ChatMessage(role="assistant", content=response))

if st.session_state.get("last_run"):
    run_url = get_run_url(st.session_state.last_run)
    st.sidebar.markdown(f"[LangSmith ì¶”ì ğŸ› ï¸]({run_url})")
