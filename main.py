import prompt as pt
from datetime import datetime

import streamlit as st
from dotenv import load_dotenv
from langchain.schema import ChatMessage
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_openai import ChatOpenAI

import prompt as pt
import search
from config import ls_configure, get_run_url

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í™˜ê²½ì„¤ì •
ls_configure()

# If user inputs a new prompt, generate and draw a new response
msgs = StreamlitChatMessageHistory(key="langchain_messages")

# sidebar êµ¬ì„±
with st.sidebar as sidebar:
    st.title(":books: :blue[  OO ì¦ê¶Œ]")
    st.session_state["select_event"] = st.selectbox('How do you want to find data?',
                                                    ['ì¢…ëª©ë‰´ìŠ¤ ìš”ì•½', 'ì¬ë¬´ì •ë³´ ìš”ì•½', 'ì£¼ì‹ì •ë³´ ë¶„ì„', 'ì¦ê¶Œì•½ê´€ ë¶„ì„'])
    st.markdown('## Models and Parameters')
    st.session_state["temperature"] = st.slider('temperature Range (0.0 ~ 2.0 )', 0.0, 2.0, 0.0)  # min, max, default
    st.session_state["model_name"] = st.selectbox('chose a model name', ['gpt-3.5-turbo', 'gpt-4'])
    if st.session_state["select_event"] == 'ì¦ê¶Œì•½ê´€ ë¶„ì„':
        uploaded_file = st.sidebar.file_uploader("upload your pdf file", type=['pdf'])
        if uploaded_file:
            st.session_state['uploaded_file'] = uploaded_file
        if 'uploaded_file' in st.session_state and 'retriever' not in st.session_state:
            pt.make_prompt_by_file(st.session_state["select_event"])
    expander = st.expander("## About ")
    expander.write(""" 
                Introducing Stock Summary and Financial Information Summarization with Generative AI (LLM)
                And Users can easily find the information they need in various documents, including securities terms and conditions.
                """)
    reset_history = st.button("ì±„íŒ… ì´ˆê¸°í™”")

# main êµ¬ì„±
select_event = st.session_state["select_event"]
if select_event == 'ì¢…ëª©ë‰´ìŠ¤ ìš”ì•½':
    st.title('Stock New Summary')
    st.markdown("""* Never News API ë“±ì„ í†µí•œ ì‚¬ì—…ì(ì¢…ëª©)ì— ëŒ€í•œ ë‰´ìŠ¤ ìš”ì•½ì„ í•´ë“œë¦½ë‹ˆë‹¤.""")
elif select_event == 'ì¬ë¬´ì •ë³´ ìš”ì•½':
    st.title('Financial Information Summary')
    st.markdown("""* DART APIë¥¼ í†µí•œ ì‚¬ì—…ì(ì¢…ëª©)ì— ëŒ€í•œ ì¬ë¬´ì •ë³´ ìš”ì•½ì„ í•´ë“œë¦½ë‹ˆë‹¤.""")
elif select_event == 'ì¦ê¶Œì•½ê´€ ë¶„ì„':
    st.title('Document Analysis')
    st.markdown("""* ì¦ê¶Œì•½ê´€(pdf)ì„ ë¶„ì„í•˜ì—¬ ë‹µë³€ì„ í•´ë“œë¦½ë‹ˆë‹¤.""")
elif select_event == 'ì£¼ì‹ì •ë³´ ë¶„ì„':
    st.title('Stock Information Analysis')
    st.markdown("""* FinanceDataReaderë¥¼ í™œìš©í•˜ì—¬ ì£¼ì‹ì •ë³´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.""")
else:
    st.title('Techical Analysis')
    st.markdown("""* ì‚¬ìš©í•˜ì§€ ì•ŠìŒ """)
    context = st.text_input('ì‚¬ì—…ì(ì¢…ëª©)ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”')
    if st.button('ì£¼ì‹ì •ë³´ ë¶„ì„'):
        with st.spinner('[' + context + '] Searching ...'):
            st.text('ì¤€ë¹„ì¤‘ ì…ë‹ˆë‹¤.')

if len(msgs.messages) == 0 or reset_history:
    msgs.clear()
    msgs.add_ai_message("ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    st.session_state["last_run"] = None

if "messages" not in st.session_state:
    st.session_state["messages"] = [
        ChatMessage(role="assistant", content="ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    ]

for msg in st.session_state.messages:
    st.chat_message(msg.role).write(msg.content)

if user_input := st.chat_input():
    client = st.session_state["client"]
    run_collector = st.session_state["run_collector"]
    cfg = st.session_state["cfg"]

    search_result = ''
    if select_event == 'ì¢…ëª©ë‰´ìŠ¤ ìš”ì•½':
        search_result = search.search_by_naver_api(user_input.split()[0])
    elif select_event == 'ì¬ë¬´ì •ë³´ ìš”ì•½':
        search_result = search.search_by_dart_api(user_input.split()[0])
    elif select_event == 'ì£¼ì‹ì •ë³´ ë¶„ì„':
        start_date = datetime(datetime.now().year, 1, 1)
        end_date = datetime.now()
        search_result = search.get_yearly_price(search.item_code_by_item_name(user_input.split()[0]))
        search_result = search_result + "ëŠ” {0}ë¶€í„° {1}ê¹Œì§€ {2}ì˜ ì£¼ì‹ ê°€ê²©ì´ì•¼.".format(start_date, end_date, user_input.split()[0])

    st.session_state.messages.append(ChatMessage(role="user", content=user_input))
    st.chat_message("user").write(user_input)
    with st.chat_message("assistant"):
        stream_handler = pt.StreamHandler(st.empty())
        if select_event == 'ì¦ê¶Œì•½ê´€ ë¶„ì„':
            prompt = st.session_state["prompt"]
            retriever = st.session_state["retriever"]

            llm = ChatOpenAI(
                model=st.session_state["model_name"],
                temperature=st.session_state["temperature"],
                streaming=True,
                callbacks=[stream_handler]
            )
            chain = (
                    {
                        "context": retriever,
                        "question": RunnablePassthrough(),
                    }
                    | prompt
                    | llm
            )
            response = chain.invoke(user_input, cfg)
        else:
            chain = pt.chain_with_api(select_event)
            chain_with_history = RunnableWithMessageHistory(
                chain,
                lambda session_id: msgs,
                input_messages_key="question",
                history_messages_key="history",
            )
            response = chain_with_history.invoke({"question": user_input, "context": search_result}, cfg)
        st.session_state.messages.append(
            ChatMessage(role="assistant", content=response.content)
        )
    st.session_state.last_run = run_collector.traced_runs[0].id

if st.session_state.get("last_run"):
    run_url = get_run_url(st.session_state.last_run)
    st.sidebar.markdown(f"[LangSmith ì¶”ì ğŸ› ï¸]({run_url})")
