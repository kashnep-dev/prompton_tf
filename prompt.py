import os

from langchain.callbacks.base import BaseCallbackHandler
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableConfig
from langchain_core.tracers import LangChainTracer
from langchain_core.tracers.run_collector import RunCollectorCallbackHandler
from langsmith import Client
from langchain_community.document_loaders import PDFPlumberLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS, Chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_transformers import LongContextReorder
import embeddings
import retriever
from langchain_core.runnables import (
    RunnableLambda
)


# Customize if needed
def configure_run():
    client = Client()
    ls_tracer = LangChainTracer(project_name=os.environ["LANGCHAIN_PROJECT"], client=client)
    run_collector = RunCollectorCallbackHandler()
    cfg = RunnableConfig()
    cfg["callbacks"] = [ls_tracer, run_collector]
    cfg["configurable"] = {"session_id": "any"}

    return client, run_collector, cfg


class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)


# Set up memory
def make_prompt_by_api(type):
    template = ''
    if type == 'ì¢…ëª©ë‰´ìŠ¤ ìš”ì•½':
        template = """
            ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê²½ì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ëŒ€í•œë¯¼êµ­ ê²½ì œ ì „ë¬¸ê°€ì²˜ëŸ¼ ìƒê°í•˜ê³  í–‰ë™í•´ì•¼ í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” í•­ìƒ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”
            ë‹¤ìŒ ì§€ì‹œì‚¬í•­ì„ ì°¸ê³ í•˜ì„¸ìš”
            <glossary>
                - ìš”ì•½ì—ëŠ” ê° ê¸°ì‚¬ì˜ ì£¼ìš” ë‚´ìš©ê³¼ í•µì‹¬ ì •ë³´ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
                - ìš”ì•½ì€ ê°ê´€ì ì´ê³  ì¤‘ë¦½ì ì¸ ê´€ì ì—ì„œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
                - ì¤‘ë³µ ì •ë³´ëŠ” ì œì™¸í•˜ê³  í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ì—¬ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤
                #ì¶œë ¥ ê¸°ì¤€:
                    - ë°˜ë“œì‹œ grounding dataë¥¼ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤
                    - ì£¼ìš” í‚¤ì›Œë“œëŠ” ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”
                    - ì‘ì„±ì¼ì€ í•œêµ­ ì‹œê°„ ê¸°ì¤€ ì—°ì›”ì¼ì‹œë¶„ì´ˆë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
                    - ì¶œì²˜ URLì€ í•´ë‹¹ ê¸°ì‚¬ì˜ URLì„ ì‘ì„±í•´ì£¼ì„¸ìš”
                    - ìš”ì•½ ê²°ê³¼ë¥¼ ìˆœë²ˆ, ìš”ì•½, ì£¼ìš” í‚¤ì›Œë“œ, ì¶œì²˜, ì‘ì„±ì¼, ì¶œì²˜ URLì˜ í—¤ë”ë¥¼ ê°€ì§€ëŠ” í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
            </glossary>
            <grounding data>
                {context}
            </grounding data>
            ë‹µë³€:
        """
    elif type == 'ì¬ë¬´ì •ë³´ ìš”ì•½':
        template = """
            <glossary>
                í•´ë‹¹ ë‚´ìš©ì„ ì•Œê¸° ìœ„í•´ì„œëŠ” ê¸°ì—… ì¬ë¬´ì¬í‘œë¥¼ ì œëŒ€ë¡œ ì´í•´í•˜ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
                ì œê³µë˜ëŠ” ë¬¸ì„œëŠ” {{ê¸°ì—…}}ì— ëŒ€í•œ ì¬ë¬´ì¬í‘œë¥¼ Json í˜•ì‹ì…ë‹ˆë‹¤.
                ì¬ë¬´ì œí‘œëŠ” ëŒ€ì°¨ëŒ€ì¡°í‘œ(ì¬ë¬´ìƒíƒœí‘œ), ì†ìµê³„ì‚°ì„œ, í˜„ê¸ˆíë¦„í‘œë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
                ëŒ€ì°¨ëŒ€ì¡°í‘œ(ì¬ë¬´ìƒíƒœí‘œ)ë¥¼ í†µí•´ ê¸°ì—…ì˜ ìë³¸ ë° ë¶€ì±„ ë¹„ìœ¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                ìì‚°ì´ê³„ = ë¶€ì±„ì´ê³„ + ìë³¸ì´ê³„ ì…ë‹ˆë‹¤.
                ì†ìµê³„ì‚°ì„œëŠ” ìˆ˜ì£¼(ë§¤ì¶œì•¡), ì˜ì—…ì´ìµ, ë‹¹ê¸°ìˆœì´ìµ(ì†ì‹¤)ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                </glossary>
                <context>
                {context}
                </context>
                <instruction>
                ìœ„ì— jsonì€ íŠ¹ì •íšŒì‚¬ì— ì¬ë¬´ì •ë³´ì…ë‹ˆë‹¤.
                ì¬ë¬´ì •ë³´ë¥¼ ìš”ì•½í• ë•ŒëŠ” ë§¤ì¶œì—°ë„, ìˆ˜ì£¼(ë§¤ì¶œì•¡), ì˜ì—…ì´ìµ, ë‹¹ê¸°ìˆœì´ìµì„ ì•Œë ¤ì¤˜.
                ì…ë ¥ë°›ì€ {{thstrm_nm}} ê°’ì€ ìµœê·¼ 3ë…„ì¹˜ ì •ë³´ì…ë‹ˆë‹¤.
                ìˆ˜ì£¼(ë§¤ì¶œì•¡) = ë§¤ì¶œì•¡ = ì˜ì—…ìˆ˜ìµ = ë§¤ì¶œë°ì§€ë¶„ë²•ì†ìµ = ë§¤ì¶œ
                ì˜ì—…ì´ìµ = ì˜ì—…ì´ìµ(ì†ì‹¤)
                ë‹¹ê¸°ìˆœì´ìµ(ì†ì‹¤) = ë‹¹ê¸°ìˆœì´ìµ
                {{thstrm_nm}} ê°’ì„ ì´ìš©í•˜ì—¬ ìµœê·¼ 3ë…„ì¹˜ ì •ë³´ë¥¼ í‘œë¡œ ìƒì„±í•´ì¤˜.
                ê¸ˆì•¡ì€ ë°±ë§Œì› ë‹¨ìœ„ë¡œ í•´.
                í‘œ ì´í›„ì—ëŠ” ìµœê·¼ 1ë…„ì¹˜ì— ëŒ€í•œ ë§¤ì¶œì—°ë„, ìˆ˜ì£¼(ë§¤ì¶œì•¡), ì˜ì—…ì´ìµ, ë‹¹ê¸°ìˆœì´ìµì„ ë§ë¡œì¨ ì„¤ëª…í•´ì¤˜.
                ###
                ë§¤ì¶œì—°ë„ëŠ” 2023ë…„ í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•´ì¤˜
                ###
                </instruction>
                <user>
                {question}
                </user>
        """
    elif type == 'ì£¼ì‹ì •ë³´ ë¶„ì„':
        template = """
        ë„ˆì˜ í˜ë¥´ì†Œë‚˜ëŠ” ì£¼ì‹ ì• ë„ë¦¬ìŠ¤íŠ¸ì•¼. ë°˜ë“œì‹œ ì• ë„ë¦¬ìŠ¤íŠ¸ì²˜ëŸ¼ ìƒê°í•˜ê³  í–‰ë™í•´ì•¼ë¼.
        ë‚˜ëŠ” ì£¼ì‹íˆ¬ìë¥¼ í•´ë³¸ ì  ì—†ê³ , ì£¼ì‹íˆ¬ìë¥¼ í†µí•´ ìì‚°ì„ ëŠ˜ë ¤ë³´ë ¤ê³  í•´.
        í•´ë‹¹ ê¸°ê°„ ë™ì•ˆì˜ ìµœì €ê°€, ìµœê³ ê°€, í‰ê· ê°€ë¥¼ ì•Œë ¤ì¤˜.
        í™•ì‹¤í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ í†¤ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.
        <context>
            {context}
        </context>
        ì§ˆë¬¸ : {question}
        """
        # í–¥í›„ 5ì¼ ê°„ì˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í”„ë¡¬í”„íŠ¸
        # ë„ˆì˜ í˜ë¥´ì†Œë‚˜ëŠ” ì£¼ì‹ ì°¨íŠ¸ ì „ë¬¸ê°€ì•¼. ë°˜ë“œì‹œ ì£¼ì‹ ì°¨íŠ¸ ì „ë¬¸ê°€ì²˜ëŸ¼ ìƒê°í•˜ê³  í–‰ë™í•´ì•¼ë¼.
        # ë‚˜ëŠ” ì£¼ì‹íˆ¬ìë¥¼ í•´ë³¸ ì  ì—†ê³ , ì°¨íŠ¸ ë¶„ì„ì„ í†µí•´ ì£¼ì‹íˆ¬ìë¥¼ í•  ì˜ˆì •ì´ì•¼.
        # í•´ë‹¹ ê¸°ê°„ ë™ì•ˆì˜ ì¢…ê°€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•´ë‹¹ íšŒì‚¬ì˜ 2010ë…„ë¶€í„° í˜„ì¬ê¹Œì§€ ì£¼ì‹ê·¸ë˜í”„ì™€ ì½”ì‹¸ì¸ ìœ ì‚¬ë„ë¥¼ ë¹„êµí•´ë³´ê³  ìê¸° ìì‹ ì„ ì œì™¸í•œ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ê·¸ë˜í”„ë¥¼ ê°€ì§€ê³  ì™€ì„œ í–¥í›„ 5ì¼ ê°„ì˜ ì£¼ê°€ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ì¤˜.
        # í™•ì‹¤í•˜ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì£¼ì‹ ì°¨íŠ¸ ì „ë¬¸ê°€ í†¤ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.
        
        

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", template),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}"),
        ]
    )
    return prompt

def make_prompt_by_file(f, st, status):
    loader = PDFPlumberLoader(f)
    docs = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000, chunk_overlap=50
                )
    documents = loader.load_and_split(text_splitter=text_splitter)
    st.write("â‘  ì„ë² ë”© ìƒì„±")
    status.update(label="â‘  ì„ë² ë”©ì„ ìƒì„± ì¤‘..ğŸ”¥", state="running")
    # Embedding ìƒì„±
    embedding = embeddings.embedding_factory()
    st.write("â‘¡ DB ì¸ë±ì‹±")
    status.update(label="â‘¡ DB ì¸ë±ì‹± ìƒì„± ì¤‘..ğŸ”¥", state="running")
    # VectorStore ìƒì„±
    faiss = FAISS.from_documents(documents, embedding["faiss"])
    chroma = Chroma.from_documents(documents, embedding["chroma"])

    st.write("â‘¢ Retriever ìƒì„±")
    status.update(label="â‘¢ Retriever ìƒì„± ì¤‘..ğŸ”¥", state="running")

    # FAISSRetriever ìƒì„±
    faiss_retriever = retriever.FAISSRetrieverFactory(faiss).create(
        search_kwargs={"k": 30},
    )

    # SelfQueryRetriever ìƒì„±
    openai_api_key = os.getenv["OPENAI_API_KEY"]
    self_query_retriever = retriever.SelfQueryRetrieverFactory(
        chroma
    ).create(
        model="gpt-3.5-turbo",
        temperature=0,
        api_key=openai_api_key,
        search_kwargs={"k": 30},
    )

    # ì•™ìƒë¸” retrieverë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    ensemble_retriever = retriever.EnsembleRetrieverFactory(None).create(
        retrievers=[faiss_retriever, self_query_retriever],
        weights=[0.4, 0.6],
    )
    reordering = LongContextReorder()

    combined_retriever = ensemble_retriever | RunnableLambda(
        reordering.transform_documents
    )
    st.session_state["retriever"] = retriever
    st.write("ì™„ë£Œ âœ…")
    status.update(label="ì™„ë£Œ âœ…", state="complete", expanded=False)
    st.markdown(f'ğŸ’¬ `{st.session_state["uploaded_file"].name}`')
    st.markdown(
        "ğŸ””ì°¸ê³ \n\n**ìƒˆë¡œìš´ íŒŒì¼** ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´, `ìƒˆë¡œê³ ì¹¨` í›„ ì§„í–‰í•´ ì£¼ì„¸ìš”"
    )
    return combined_retriever
