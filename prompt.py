import tempfile

import streamlit as st
from langchain.callbacks.base import BaseCallbackHandler
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, FewShotChatMessagePromptTemplate
from langchain_openai import ChatOpenAI
from langchain_text_splitters import RecursiveCharacterTextSplitter

import embeddings
from custom_prompt_template import CustomPromptTemplate


class StreamHandler(BaseCallbackHandler):
    def __init__(self, container, initial_text=""):
        self.container = container
        self.text = initial_text

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text)


def get_prompt(template_type):
    prompt_template = ''
    prompt_instruction = ''

    if template_type == 'get_news':
        prompt_template = CustomPromptTemplate.NEWS_TEMPLATE_FEW_SHOT.value
        prompt_instruction = CustomPromptTemplate.NEWS_TEMPLATE_INSTRUCTION.value
    elif template_type == 'get_finance':
        prompt_template = CustomPromptTemplate.FINANCE_TEMPLATE_FEW_SHOT.value
        prompt_instruction = CustomPromptTemplate.FINANCE_TEMPLATE_INSTRUCTION.value
    elif template_type == 'get_stock':
        prompt_template = CustomPromptTemplate.STOCK_INFO_TEMPLATE_FEW_SHOT.value
        prompt_instruction = CustomPromptTemplate.STOCK_INFO_TEMPLATE_INSTRUCTION.value
    elif template_type == 'ì¦ê¶Œì•½ê´€ ë¶„ì„':
        prompt_template = CustomPromptTemplate.DOCUMENT_TEMPLATE_FEW_SHOT.value
        prompt_instruction = CustomPromptTemplate.DOCUMENT_TEMPLATE_INSTRUCTION.value
    elif template_type == 'Trend News':
        prompt_template = CustomPromptTemplate.TREND_NEWS_TEMPLATE_FEW_SHOT.value
        prompt_instruction = CustomPromptTemplate.TREND_NEWS_TEMPLATE_INSTRUCTION.value

    example_prompt = ChatPromptTemplate.from_messages(
        [
            ("human", "{question}:\n{context}"),
            ("ai", "{answer}")
        ]
    )

    few_shot_prompt = FewShotChatMessagePromptTemplate(
        examples=prompt_template,
        example_prompt=example_prompt,
    )
    if template_type == 'ì¦ê¶Œì•½ê´€ ë¶„ì„':
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", prompt_instruction),
                few_shot_prompt,
                ("human", "{question}\n{context}"),
            ]
        )
    else:
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", prompt_instruction),
                few_shot_prompt,
                MessagesPlaceholder(variable_name="history"),
                ("human", "{question}\n{context}"),
            ]
        )
    return prompt


def chain_with_api(template_type, model_name, temperature):
    prompt = get_prompt(template_type)
    stream_handler = StreamHandler(st.empty())
    llm = ChatOpenAI(
        model=model_name,
        temperature=temperature,
        streaming=True,
        callbacks=[stream_handler]
    )
    chain = prompt | llm
    return chain


def load_pdf(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False) as f:
        f.write(uploaded_file.read())
        f.flush()
        loader = PyPDFLoader(f.name)
        docs = loader.load()
    return docs


def make_prompt_by_file(search_type, uploaded_file):
    prompt = get_prompt(search_type)
    docs = load_pdf(uploaded_file)

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=500)
    splits = text_splitter.split_documents(docs)

    with st.status("íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..", expanded=True) as status:
        st.write("â‘  ì„ë² ë”© ìƒì„±")
        status.update(label="â‘  ì„ë² ë”©ì„ ìƒì„± ì¤‘..ğŸ”¥", state="running")
        embedding = embeddings.embedding_factory()

        st.write("â‘¡ DB ì¸ë±ì‹±")
        status.update(label="â‘¡ DB ì¸ë±ì‹± ìƒì„± ì¤‘..ğŸ”¥", state="running")
        faiss = FAISS.from_documents(splits, embedding["faiss"])

        st.write("â‘¢ Retriever ìƒì„±")
        status.update(label="â‘¢ Retriever ìƒì„± ì¤‘..ğŸ”¥", state="running")
        faiss_retriever = faiss.as_retriever()

        st.write("ì™„ë£Œ âœ…")
        status.update(label="ì™„ë£Œ âœ…", state="complete", expanded=False)
        st.markdown(f'ğŸ’¬ `{uploaded_file.name}`')
        st.markdown("ğŸ””ì°¸ê³ \n\n**ìƒˆë¡œìš´ íŒŒì¼** ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´, `ìƒˆë¡œê³ ì¹¨` í›„ ì§„í–‰í•´ ì£¼ì„¸ìš”")
        return faiss_retriever, prompt
